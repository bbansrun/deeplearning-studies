{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모두를 위한 머신러닝/딥러닝 5강\n",
    "## Logistic(regression) classification\n",
    "\n",
    "### Regression(HCG)\n",
    "가설, 코스트함수, 코스트 최소화과정\n",
    "\n",
    "### Binary Classification \n",
    "두개중 하나를 선택하는 것\n",
    "ex) \n",
    "메일이 스팸인가 아닌가\n",
    "facebook feed : show or hide\n",
    "credit card fraudulent Transaction detection : legitimate/fraud\n",
    "#### 0,1 encoding\n",
    "주식시작에서 살 것인가 팔것인가\n",
    "\n",
    "### Linear Regression?\n",
    "Linear regression 활용\n",
    "일정 범위 밑이라면 fail\n",
    "일정 범위 위라면 pass\n",
    "\n",
    "But 일정 선이 기울경우 문제가 생길 수 있음\n",
    "결과 값이 0,1로 나와야하나 linear regression을 사용할 경우 훨씬 작거나 큰 값으로 나올 수 있음\n",
    "\n",
    "### Logistic Hypothesis\n",
    "g(z) = 1/ (1+e^-z)\n",
    "sigmoid 함수를 활용함 (결과값이 -1 ~ 1로 수렴함)\n",
    "\n",
    "z = WX\n",
    "H(x) = g(z)\n",
    "H(X) = 1/ (1+e^-WX)\n",
    "\n",
    "\n",
    "## 5-2 Logistic classification: cost func. & gradient decent\n",
    "\n",
    "### Cost func. \n",
    "가설이 바뀌었기 때문에 cost func. 이 변경됨.\n",
    "바뀐 가설로 cost func. 을 그리게 되면 그래프가 울퉁불퉁 해짐\n",
    "-> 최저점을 찾다가 0이되는 기울기를 만날 수 있음 (local minimum)\n",
    "-> so. 이 형태의 함수를 사용할 수 없음\n",
    "\n",
    "### New cost func. for logistic\n",
    "cost(W) = m합c(H(X),y)\n",
    "c(H(x),y) = -log(H(x)) : y=1  / -log(1-H(x)) : y=0\n",
    "cost -> 실제값과 주어진 값의 차이를 말함\n",
    "\n",
    "y=1\n",
    "H(x) = 1 -> cost(1) = 0\n",
    "H(x) = 0 -> cost 는 무한대\n",
    "\n",
    "y=0\n",
    "H(x) = 0 -> cost = 0\n",
    "H(x) = 1 -> cost 는 무한대\n",
    "\n",
    "log 함수를 활용하여 cost의 목표와 맞는 함수를 설계\n",
    "\n",
    "C(H(x), y) = -ylog(H(x)) - (1-y)log(1-H(x))\n",
    "\n",
    "### Minimize cost - Gradient decent algo.\n",
    "컴퓨터로 미분하세요~~~\n",
    "\n",
    "~~~python\n",
    "#cost func.\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis)))\n",
    "\n",
    "# minimize\n",
    "a = tf.Variable(0.1) #Learning rate, alpha\n",
    "optimizer = tf.train.GradientDescentOptimizer(a) #라이브러리 활용\n",
    "train = optimizer.minimize(cost)\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "0 1.7307829\n",
      "200 0.5715119\n",
      "400 0.5074139\n",
      "600 0.4718242\n",
      "800 0.44758478\n",
      "1000 0.42857102\n",
      "1200 0.41232458\n",
      "1400 0.39775515\n",
      "1600 0.3843378\n",
      "1800 0.3718011\n",
      "2000 0.35999322\n",
      "2200 0.3488221\n",
      "2400 0.33822623\n",
      "2600 0.32816055\n",
      "2800 0.318589\n",
      "3000 0.30948085\n",
      "3200 0.30080852\n",
      "3400 0.29254702\n",
      "3600 0.28467283\n",
      "3800 0.27716395\n",
      "4000 0.2699997\n",
      "4200 0.2631606\n",
      "4400 0.2566281\n",
      "4600 0.25038514\n",
      "4800 0.24441506\n",
      "5000 0.2387027\n",
      "5200 0.23323365\n",
      "5400 0.22799426\n",
      "5600 0.22297196\n",
      "5800 0.21815471\n",
      "6000 0.2135315\n",
      "6200 0.20909168\n",
      "6400 0.20482552\n",
      "6600 0.20072377\n",
      "6800 0.19677766\n",
      "7000 0.19297926\n",
      "7200 0.18932097\n",
      "7400 0.1857955\n",
      "7600 0.18239635\n",
      "7800 0.17911713\n",
      "8000 0.17595182\n",
      "8200 0.17289507\n",
      "8400 0.16994143\n",
      "8600 0.16708624\n",
      "8800 0.1643247\n",
      "9000 0.16165249\n",
      "9200 0.15906553\n",
      "9400 0.1565599\n",
      "9600 0.15413195\n",
      "9800 0.1517783\n",
      "10000 0.1494956\n",
      "\n",
      "Hypothesis:  [[0.03074026]\n",
      " [0.15884683]\n",
      " [0.3048674 ]\n",
      " [0.78138196]\n",
      " [0.93957496]\n",
      " [0.9801688 ]] \n",
      "Correct (Y):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Lab 5 Logistic Regression Classifier\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[1, 2],\n",
    "          [2, 3],\n",
    "          [3, 1],\n",
    "          [4, 3],\n",
    "          [5, 3],\n",
    "          [6, 2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "#feed dict 를 만들 경우 shape 에 신경을 써야함 None = N개\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "#W -> [들어오는 값, 나가는 값]\n",
    "#b -> [나가는 값]\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "# tf에 있는 수학 함수를 활용하여 계산\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "#cost minimize과정\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "#0.5기준 pass/fail\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759, 8) (759, 1)\n",
      "0 0.974222\n",
      "200 0.73380584\n",
      "400 0.68054277\n",
      "600 0.6573832\n",
      "800 0.6405061\n",
      "1000 0.6259895\n",
      "1200 0.61303777\n",
      "1400 0.6013963\n",
      "1600 0.5909146\n",
      "1800 0.5814696\n",
      "2000 0.5729515\n",
      "2200 0.5652617\n",
      "2400 0.5583115\n",
      "2600 0.5520215\n",
      "2800 0.5463204\n",
      "3000 0.54114515\n",
      "3200 0.53643954\n",
      "3400 0.53215367\n",
      "3600 0.5282432\n",
      "3800 0.5246693\n",
      "4000 0.52139693\n",
      "4200 0.51839536\n",
      "4400 0.5156375\n",
      "4600 0.51309913\n",
      "4800 0.5107587\n",
      "5000 0.5085972\n",
      "5200 0.5065978\n",
      "5400 0.5047451\n",
      "5600 0.5030261\n",
      "5800 0.5014283\n",
      "6000 0.4999411\n",
      "6200 0.498555\n",
      "6400 0.49726117\n",
      "6600 0.49605185\n",
      "6800 0.49492007\n",
      "7000 0.49385956\n",
      "7200 0.49286455\n",
      "7400 0.49193004\n",
      "7600 0.4910512\n",
      "7800 0.4902238\n",
      "8000 0.4894441\n",
      "8200 0.48870835\n",
      "8400 0.48801363\n",
      "8600 0.48735693\n",
      "8800 0.4867357\n",
      "9000 0.4861473\n",
      "9200 0.48558944\n",
      "9400 0.4850604\n",
      "9600 0.4845582\n",
      "9800 0.4840809\n",
      "10000 0.48362702\n",
      "\n",
      "Hypothesis:  [[0.37003186]\n",
      " [0.91548055]\n",
      " [0.21602738]\n",
      " [0.9483494 ]\n",
      " [0.08354768]\n",
      " [0.7647524 ]\n",
      " [0.94660914]\n",
      " [0.6240098 ]\n",
      " [0.24575198]\n",
      " [0.53068644]\n",
      " [0.70052207]\n",
      " [0.17214665]\n",
      " [0.16543275]\n",
      " [0.21994296]\n",
      " [0.71247756]\n",
      " [0.45385256]\n",
      " [0.7328221 ]\n",
      " [0.86161494]\n",
      " [0.8147425 ]\n",
      " [0.5555971 ]\n",
      " [0.6401038 ]\n",
      " [0.10689524]\n",
      " [0.683552  ]\n",
      " [0.74390626]\n",
      " [0.36421013]\n",
      " [0.93936753]\n",
      " [0.6559927 ]\n",
      " [0.62544465]\n",
      " [0.65211356]\n",
      " [0.40692753]\n",
      " [0.9621741 ]\n",
      " [0.87790984]\n",
      " [0.58168435]\n",
      " [0.78780305]\n",
      " [0.3750869 ]\n",
      " [0.6011569 ]\n",
      " [0.7843533 ]\n",
      " [0.3977098 ]\n",
      " [0.5350237 ]\n",
      " [0.31824097]\n",
      " [0.8445039 ]\n",
      " [0.15713444]\n",
      " [0.41641986]\n",
      " [0.03135976]\n",
      " [0.52673364]\n",
      " [0.915929  ]\n",
      " [0.70154345]\n",
      " [0.7093997 ]\n",
      " [0.9460212 ]\n",
      " [0.9376935 ]\n",
      " [0.9446371 ]\n",
      " [0.24789682]\n",
      " [0.32195857]\n",
      " [0.9602661 ]\n",
      " [0.23895976]\n",
      " [0.4262069 ]\n",
      " [0.06667963]\n",
      " [0.75892603]\n",
      " [0.8410173 ]\n",
      " [0.5098418 ]\n",
      " [0.93055457]\n",
      " [0.70813584]\n",
      " [0.6522975 ]\n",
      " [0.85724926]\n",
      " [0.54217255]\n",
      " [0.45803586]\n",
      " [0.9648669 ]\n",
      " [0.760651  ]\n",
      " [0.8371695 ]\n",
      " [0.70461416]\n",
      " [0.2525223 ]\n",
      " [0.7577009 ]\n",
      " [0.9056169 ]\n",
      " [0.929743  ]\n",
      " [0.8595284 ]\n",
      " [0.77625084]\n",
      " [0.42486444]\n",
      " [0.8666398 ]\n",
      " [0.9081012 ]\n",
      " [0.91360456]\n",
      " [0.86388415]\n",
      " [0.8441913 ]\n",
      " [0.36394185]\n",
      " [0.80408204]\n",
      " [0.55200076]\n",
      " [0.88440704]\n",
      " [0.5241623 ]\n",
      " [0.90309423]\n",
      " [0.9285146 ]\n",
      " [0.79115593]\n",
      " [0.8253182 ]\n",
      " [0.64373755]\n",
      " [0.7171906 ]\n",
      " [0.62347317]\n",
      " [0.90414244]\n",
      " [0.9790907 ]\n",
      " [0.9090113 ]\n",
      " [0.58464134]\n",
      " [0.16190979]\n",
      " [0.6583708 ]\n",
      " [0.6359273 ]\n",
      " [0.965997  ]\n",
      " [0.67171514]\n",
      " [0.7229756 ]\n",
      " [0.8866031 ]\n",
      " [0.7276777 ]\n",
      " [0.9305426 ]\n",
      " [0.8626789 ]\n",
      " [0.56823206]\n",
      " [0.3295837 ]\n",
      " [0.9432294 ]\n",
      " [0.8515173 ]\n",
      " [0.4482201 ]\n",
      " [0.39299121]\n",
      " [0.62763   ]\n",
      " [0.7908457 ]\n",
      " [0.8589479 ]\n",
      " [0.93857807]\n",
      " [0.14030883]\n",
      " [0.729022  ]\n",
      " [0.86476177]\n",
      " [0.6166415 ]\n",
      " [0.64215124]\n",
      " [0.7795744 ]\n",
      " [0.7059267 ]\n",
      " [0.8574369 ]\n",
      " [0.82025975]\n",
      " [0.54896337]\n",
      " [0.5704984 ]\n",
      " [0.3185801 ]\n",
      " [0.4587792 ]\n",
      " [0.7533742 ]\n",
      " [0.938213  ]\n",
      " [0.8635385 ]\n",
      " [0.8011608 ]\n",
      " [0.8701301 ]\n",
      " [0.42006522]\n",
      " [0.81549966]\n",
      " [0.72602177]\n",
      " [0.71848154]\n",
      " [0.89642787]\n",
      " [0.6353291 ]\n",
      " [0.6105171 ]\n",
      " [0.67205024]\n",
      " [0.9115739 ]\n",
      " [0.6491893 ]\n",
      " [0.44098893]\n",
      " [0.9371995 ]\n",
      " [0.63372016]\n",
      " [0.7613014 ]\n",
      " [0.23399186]\n",
      " [0.3268023 ]\n",
      " [0.12558195]\n",
      " [0.23778126]\n",
      " [0.90760034]\n",
      " [0.8623409 ]\n",
      " [0.95348275]\n",
      " [0.1255207 ]\n",
      " [0.53432935]\n",
      " [0.80264574]\n",
      " [0.64998204]\n",
      " [0.8487989 ]\n",
      " [0.38238317]\n",
      " [0.79798627]\n",
      " [0.63381225]\n",
      " [0.5795338 ]\n",
      " [0.6932558 ]\n",
      " [0.88282454]\n",
      " [0.7700525 ]\n",
      " [0.64941114]\n",
      " [0.8525299 ]\n",
      " [0.85940075]\n",
      " [0.9539152 ]\n",
      " [0.24065179]\n",
      " [0.79474664]\n",
      " [0.27039856]\n",
      " [0.37937933]\n",
      " [0.3092518 ]\n",
      " [0.88998455]\n",
      " [0.6877978 ]\n",
      " [0.932184  ]\n",
      " [0.9017601 ]\n",
      " [0.59797454]\n",
      " [0.13032869]\n",
      " [0.17434561]\n",
      " [0.52043444]\n",
      " [0.7481282 ]\n",
      " [0.6766156 ]\n",
      " [0.8281049 ]\n",
      " [0.6600339 ]\n",
      " [0.36263263]\n",
      " [0.18541753]\n",
      " [0.9092251 ]\n",
      " [0.4136732 ]\n",
      " [0.85321283]\n",
      " [0.9062588 ]\n",
      " [0.68145704]\n",
      " [0.6851039 ]\n",
      " [0.56336015]\n",
      " [0.5532917 ]\n",
      " [0.67773235]\n",
      " [0.9587245 ]\n",
      " [0.7710124 ]\n",
      " [0.8127992 ]\n",
      " [0.13762414]\n",
      " [0.3309636 ]\n",
      " [0.90895224]\n",
      " [0.22505349]\n",
      " [0.93034935]\n",
      " [0.27977684]\n",
      " [0.28565747]\n",
      " [0.52054805]\n",
      " [0.7501162 ]\n",
      " [0.20570871]\n",
      " [0.75803435]\n",
      " [0.74818885]\n",
      " [0.7201228 ]\n",
      " [0.64906794]\n",
      " [0.11264303]\n",
      " [0.27403605]\n",
      " [0.71924555]\n",
      " [0.507519  ]\n",
      " [0.92561567]\n",
      " [0.94974613]\n",
      " [0.70573455]\n",
      " [0.3314457 ]\n",
      " [0.0124335 ]\n",
      " [0.7328249 ]\n",
      " [0.31322718]\n",
      " [0.45518637]\n",
      " [0.95113003]\n",
      " [0.6119205 ]\n",
      " [0.956211  ]\n",
      " [0.21247816]\n",
      " [0.13730332]\n",
      " [0.2640965 ]\n",
      " [0.746002  ]\n",
      " [0.90616345]\n",
      " [0.8902337 ]\n",
      " [0.63888246]\n",
      " [0.5905467 ]\n",
      " [0.6142768 ]\n",
      " [0.11803737]\n",
      " [0.5649264 ]\n",
      " [0.12032914]\n",
      " [0.594708  ]\n",
      " [0.8765245 ]\n",
      " [0.65327024]\n",
      " [0.7013043 ]\n",
      " [0.9605941 ]\n",
      " [0.8171557 ]\n",
      " [0.7480624 ]\n",
      " [0.7085493 ]\n",
      " [0.73317325]\n",
      " [0.8715658 ]\n",
      " [0.38832116]\n",
      " [0.4888562 ]\n",
      " [0.45576382]\n",
      " [0.78635186]\n",
      " [0.6569421 ]\n",
      " [0.67967415]\n",
      " [0.7809389 ]\n",
      " [0.26716095]\n",
      " [0.37469894]\n",
      " [0.47442523]\n",
      " [0.62990814]\n",
      " [0.3152073 ]\n",
      " [0.9203259 ]\n",
      " [0.7605115 ]\n",
      " [0.9225775 ]\n",
      " [0.56285393]\n",
      " [0.754199  ]\n",
      " [0.82398236]\n",
      " [0.84951985]\n",
      " [0.60194135]\n",
      " [0.8399878 ]\n",
      " [0.3606706 ]\n",
      " [0.6481596 ]\n",
      " [0.739785  ]\n",
      " [0.38866502]\n",
      " [0.79204816]\n",
      " [0.24882403]\n",
      " [0.54820836]\n",
      " [0.9495237 ]\n",
      " [0.81041384]\n",
      " [0.86216223]\n",
      " [0.696165  ]\n",
      " [0.38970423]\n",
      " [0.62187254]\n",
      " [0.41834182]\n",
      " [0.47441807]\n",
      " [0.651903  ]\n",
      " [0.65728635]\n",
      " [0.6830765 ]\n",
      " [0.54236895]\n",
      " [0.18214154]\n",
      " [0.70659906]\n",
      " [0.92117083]\n",
      " [0.4837174 ]\n",
      " [0.64411545]\n",
      " [0.7906146 ]\n",
      " [0.55168736]\n",
      " [0.78574437]\n",
      " [0.43543458]\n",
      " [0.6656115 ]\n",
      " [0.8926581 ]\n",
      " [0.66950226]\n",
      " [0.7405897 ]\n",
      " [0.8683181 ]\n",
      " [0.4409264 ]\n",
      " [0.8741252 ]\n",
      " [0.95516   ]\n",
      " [0.31215012]\n",
      " [0.81482506]\n",
      " [0.28057498]\n",
      " [0.7848169 ]\n",
      " [0.81692725]\n",
      " [0.72387695]\n",
      " [0.40729517]\n",
      " [0.77939034]\n",
      " [0.7963444 ]\n",
      " [0.72602904]\n",
      " [0.21197817]\n",
      " [0.8400166 ]\n",
      " [0.88320935]\n",
      " [0.43998405]\n",
      " [0.9536884 ]\n",
      " [0.24628603]\n",
      " [0.7256563 ]\n",
      " [0.9585662 ]\n",
      " [0.25511128]\n",
      " [0.38668022]\n",
      " [0.66522104]\n",
      " [0.32212335]\n",
      " [0.18379894]\n",
      " [0.8639181 ]\n",
      " [0.91269827]\n",
      " [0.8421713 ]\n",
      " [0.61256695]\n",
      " [0.61782426]\n",
      " [0.61188555]\n",
      " [0.7783388 ]\n",
      " [0.81998533]\n",
      " [0.9470573 ]\n",
      " [0.7201809 ]\n",
      " [0.74858665]\n",
      " [0.59124976]\n",
      " [0.92642975]\n",
      " [0.94356465]\n",
      " [0.65994716]\n",
      " [0.28874373]\n",
      " [0.6326212 ]\n",
      " [0.34376186]\n",
      " [0.7872473 ]\n",
      " [0.18558839]\n",
      " [0.26064605]\n",
      " [0.42378932]\n",
      " [0.66341966]\n",
      " [0.32271576]\n",
      " [0.5886754 ]\n",
      " [0.85246617]\n",
      " [0.6462896 ]\n",
      " [0.8607625 ]\n",
      " [0.9566511 ]\n",
      " [0.78148973]\n",
      " [0.03902066]\n",
      " [0.3468342 ]\n",
      " [0.84605324]\n",
      " [0.8765325 ]\n",
      " [0.6374535 ]\n",
      " [0.27857935]\n",
      " [0.9115516 ]\n",
      " [0.8942279 ]\n",
      " [0.29613295]\n",
      " [0.5700543 ]\n",
      " [0.8259093 ]\n",
      " [0.8669205 ]\n",
      " [0.83554876]\n",
      " [0.8723941 ]\n",
      " [0.89825463]\n",
      " [0.93942595]\n",
      " [0.6399861 ]\n",
      " [0.6104679 ]\n",
      " [0.5533838 ]\n",
      " [0.8144549 ]\n",
      " [0.8708997 ]\n",
      " [0.2333422 ]\n",
      " [0.7985961 ]\n",
      " [0.89199746]\n",
      " [0.27992702]\n",
      " [0.48323697]\n",
      " [0.83799076]\n",
      " [0.5846791 ]\n",
      " [0.9026145 ]\n",
      " [0.3026297 ]\n",
      " [0.8302666 ]\n",
      " [0.6704346 ]\n",
      " [0.87681425]\n",
      " [0.38466316]\n",
      " [0.6947967 ]\n",
      " [0.69458514]\n",
      " [0.7947795 ]\n",
      " [0.07643867]\n",
      " [0.17290846]\n",
      " [0.6348562 ]\n",
      " [0.8155424 ]\n",
      " [0.3817097 ]\n",
      " [0.8198056 ]\n",
      " [0.5048051 ]\n",
      " [0.38023198]\n",
      " [0.7809728 ]\n",
      " [0.4258755 ]\n",
      " [0.8984246 ]\n",
      " [0.8508325 ]\n",
      " [0.65622354]\n",
      " [0.91650057]\n",
      " [0.6692599 ]\n",
      " [0.77402496]\n",
      " [0.35418713]\n",
      " [0.32064432]\n",
      " [0.75412345]\n",
      " [0.46952873]\n",
      " [0.52253413]\n",
      " [0.9015024 ]\n",
      " [0.89992666]\n",
      " [0.91271305]\n",
      " [0.95233107]\n",
      " [0.7015096 ]\n",
      " [0.83610046]\n",
      " [0.38574636]\n",
      " [0.39738074]\n",
      " [0.47271675]\n",
      " [0.9415037 ]\n",
      " [0.5340127 ]\n",
      " [0.18898869]\n",
      " [0.9329737 ]\n",
      " [0.84650695]\n",
      " [0.49440587]\n",
      " [0.80312306]\n",
      " [0.00960752]\n",
      " [0.92079556]\n",
      " [0.8005519 ]\n",
      " [0.782111  ]\n",
      " [0.8203358 ]\n",
      " [0.9680126 ]\n",
      " [0.6016943 ]\n",
      " [0.79016757]\n",
      " [0.64055496]\n",
      " [0.8574066 ]\n",
      " [0.23814833]\n",
      " [0.54446757]\n",
      " [0.9211141 ]\n",
      " [0.6331614 ]\n",
      " [0.7630992 ]\n",
      " [0.93186295]\n",
      " [0.83781093]\n",
      " [0.8797304 ]\n",
      " [0.44431302]\n",
      " [0.81623125]\n",
      " [0.9568143 ]\n",
      " [0.75897527]\n",
      " [0.6570054 ]\n",
      " [0.32950932]\n",
      " [0.4197823 ]\n",
      " [0.5713799 ]\n",
      " [0.6386368 ]\n",
      " [0.53501093]\n",
      " [0.7883034 ]\n",
      " [0.59427124]\n",
      " [0.7511472 ]\n",
      " [0.8545512 ]\n",
      " [0.7967293 ]\n",
      " [0.6231361 ]\n",
      " [0.5059156 ]\n",
      " [0.6136735 ]\n",
      " [0.94594324]\n",
      " [0.86947984]\n",
      " [0.23167524]\n",
      " [0.47079158]\n",
      " [0.43242714]\n",
      " [0.08282861]\n",
      " [0.88935137]\n",
      " [0.14215669]\n",
      " [0.89593863]\n",
      " [0.8619416 ]\n",
      " [0.834408  ]\n",
      " [0.62860477]\n",
      " [0.88424885]\n",
      " [0.35417128]\n",
      " [0.77151746]\n",
      " [0.9407079 ]\n",
      " [0.389432  ]\n",
      " [0.42330426]\n",
      " [0.8894435 ]\n",
      " [0.86383   ]\n",
      " [0.58552647]\n",
      " [0.80563533]\n",
      " [0.79816794]\n",
      " [0.7988252 ]\n",
      " [0.35251018]\n",
      " [0.74067354]\n",
      " [0.8714471 ]\n",
      " [0.5967558 ]\n",
      " [0.7951093 ]\n",
      " [0.7616224 ]\n",
      " [0.80735326]\n",
      " [0.83968353]\n",
      " [0.947065  ]\n",
      " [0.6730312 ]\n",
      " [0.40919766]\n",
      " [0.7824322 ]\n",
      " [0.7520776 ]\n",
      " [0.97216964]\n",
      " [0.79477125]\n",
      " [0.7043549 ]\n",
      " [0.37024307]\n",
      " [0.72415984]\n",
      " [0.9112206 ]\n",
      " [0.95512813]\n",
      " [0.92075676]\n",
      " [0.7272074 ]\n",
      " [0.62702626]\n",
      " [0.8090792 ]\n",
      " [0.4219896 ]\n",
      " [0.768348  ]\n",
      " [0.77097964]\n",
      " [0.8537084 ]\n",
      " [0.6119234 ]\n",
      " [0.70903116]\n",
      " [0.8534461 ]\n",
      " [0.48009148]\n",
      " [0.47600704]\n",
      " [0.633771  ]\n",
      " [0.7343564 ]\n",
      " [0.5865755 ]\n",
      " [0.9221809 ]\n",
      " [0.928028  ]\n",
      " [0.24493489]\n",
      " [0.11743271]\n",
      " [0.80530167]\n",
      " [0.55715525]\n",
      " [0.22469112]\n",
      " [0.8327049 ]\n",
      " [0.9014041 ]\n",
      " [0.6787964 ]\n",
      " [0.9412496 ]\n",
      " [0.915044  ]\n",
      " [0.8018216 ]\n",
      " [0.82581055]\n",
      " [0.68717337]\n",
      " [0.5779414 ]\n",
      " [0.7635423 ]\n",
      " [0.61091614]\n",
      " [0.14149427]\n",
      " [0.90590143]\n",
      " [0.89553386]\n",
      " [0.68140393]\n",
      " [0.9151058 ]\n",
      " [0.8662422 ]\n",
      " [0.9031191 ]\n",
      " [0.6343756 ]\n",
      " [0.74434733]\n",
      " [0.86853504]\n",
      " [0.714225  ]\n",
      " [0.87389636]\n",
      " [0.92433685]\n",
      " [0.53835934]\n",
      " [0.82471573]\n",
      " [0.82216066]\n",
      " [0.45614842]\n",
      " [0.5516043 ]\n",
      " [0.07508859]\n",
      " [0.2554174 ]\n",
      " [0.844239  ]\n",
      " [0.6626982 ]\n",
      " [0.67233986]\n",
      " [0.4898188 ]\n",
      " [0.9319752 ]\n",
      " [0.46693408]\n",
      " [0.8121207 ]\n",
      " [0.2304917 ]\n",
      " [0.8926242 ]\n",
      " [0.27195418]\n",
      " [0.7992072 ]\n",
      " [0.5422217 ]\n",
      " [0.77505684]\n",
      " [0.5572491 ]\n",
      " [0.27887404]\n",
      " [0.772218  ]\n",
      " [0.9362968 ]\n",
      " [0.39858437]\n",
      " [0.9279789 ]\n",
      " [0.8626441 ]\n",
      " [0.8539331 ]\n",
      " [0.8187632 ]\n",
      " [0.42240223]\n",
      " [0.34413052]\n",
      " [0.64388883]\n",
      " [0.13661328]\n",
      " [0.9541315 ]\n",
      " [0.39051208]\n",
      " [0.93976825]\n",
      " [0.89578676]\n",
      " [0.43772215]\n",
      " [0.18767709]\n",
      " [0.63602334]\n",
      " [0.468482  ]\n",
      " [0.8321993 ]\n",
      " [0.71974903]\n",
      " [0.98327374]\n",
      " [0.43412197]\n",
      " [0.6611377 ]\n",
      " [0.79943466]\n",
      " [0.6589147 ]\n",
      " [0.04487872]\n",
      " [0.76604   ]\n",
      " [0.79205453]\n",
      " [0.8538984 ]\n",
      " [0.6441347 ]\n",
      " [0.4521045 ]\n",
      " [0.6059911 ]\n",
      " [0.90392005]\n",
      " [0.58050025]\n",
      " [0.8184375 ]\n",
      " [0.8036426 ]\n",
      " [0.8884411 ]\n",
      " [0.8134402 ]\n",
      " [0.56198764]\n",
      " [0.78616697]\n",
      " [0.90039146]\n",
      " [0.6773124 ]\n",
      " [0.96727574]\n",
      " [0.80911094]\n",
      " [0.615409  ]\n",
      " [0.5025051 ]\n",
      " [0.7920008 ]\n",
      " [0.83763254]\n",
      " [0.4987446 ]\n",
      " [0.6958789 ]\n",
      " [0.2885709 ]\n",
      " [0.63699603]\n",
      " [0.8366306 ]\n",
      " [0.9552349 ]\n",
      " [0.84366626]\n",
      " [0.7700925 ]\n",
      " [0.729997  ]\n",
      " [0.90502757]\n",
      " [0.49800137]\n",
      " [0.94460726]\n",
      " [0.46422267]\n",
      " [0.79023653]\n",
      " [0.34313148]\n",
      " [0.05604661]\n",
      " [0.3349306 ]\n",
      " [0.362182  ]\n",
      " [0.69808364]\n",
      " [0.8445837 ]\n",
      " [0.58753747]\n",
      " [0.76824254]\n",
      " [0.81240606]\n",
      " [0.5903642 ]\n",
      " [0.39017192]\n",
      " [0.8804146 ]\n",
      " [0.9080004 ]\n",
      " [0.34558284]\n",
      " [0.60365367]\n",
      " [0.20400009]\n",
      " [0.4146667 ]\n",
      " [0.74312055]\n",
      " [0.7132845 ]\n",
      " [0.895306  ]\n",
      " [0.9793978 ]\n",
      " [0.20553094]\n",
      " [0.75263506]\n",
      " [0.5752076 ]\n",
      " [0.37561542]\n",
      " [0.72091997]\n",
      " [0.73230755]\n",
      " [0.89490426]\n",
      " [0.7099158 ]\n",
      " [0.4939478 ]\n",
      " [0.58987445]\n",
      " [0.17812285]\n",
      " [0.6506132 ]\n",
      " [0.5504319 ]\n",
      " [0.9054696 ]\n",
      " [0.598595  ]\n",
      " [0.6383472 ]\n",
      " [0.80110824]\n",
      " [0.7368445 ]\n",
      " [0.37900403]\n",
      " [0.75590736]\n",
      " [0.6150167 ]\n",
      " [0.26063642]\n",
      " [0.580967  ]\n",
      " [0.9117863 ]\n",
      " [0.8376616 ]\n",
      " [0.6030847 ]\n",
      " [0.8069207 ]\n",
      " [0.3227334 ]\n",
      " [0.8301623 ]\n",
      " [0.62737674]\n",
      " [0.7877811 ]\n",
      " [0.40930733]\n",
      " [0.68117344]\n",
      " [0.8340646 ]\n",
      " [0.15815163]\n",
      " [0.27007002]\n",
      " [0.78574777]\n",
      " [0.8140861 ]\n",
      " [0.76922274]\n",
      " [0.9012736 ]\n",
      " [0.7859848 ]\n",
      " [0.7243077 ]\n",
      " [0.76133776]\n",
      " [0.7465561 ]\n",
      " [0.6866914 ]\n",
      " [0.7927315 ]\n",
      " [0.5083558 ]\n",
      " [0.46117187]\n",
      " [0.8820466 ]\n",
      " [0.827842  ]\n",
      " [0.66061914]\n",
      " [0.29658586]\n",
      " [0.88612473]\n",
      " [0.7696434 ]\n",
      " [0.82751465]\n",
      " [0.69222766]\n",
      " [0.86061233]\n",
      " [0.8621819 ]\n",
      " [0.73982066]\n",
      " [0.40291804]\n",
      " [0.9043559 ]\n",
      " [0.92673653]\n",
      " [0.29239354]\n",
      " [0.14486504]\n",
      " [0.75177014]\n",
      " [0.38205963]\n",
      " [0.7350757 ]\n",
      " [0.36591643]\n",
      " [0.47245234]\n",
      " [0.33215332]\n",
      " [0.7976326 ]\n",
      " [0.873673  ]\n",
      " [0.15875709]\n",
      " [0.37841165]\n",
      " [0.5407496 ]\n",
      " [0.49625942]\n",
      " [0.51185215]\n",
      " [0.77610594]\n",
      " [0.16323736]\n",
      " [0.9135155 ]\n",
      " [0.19408873]\n",
      " [0.8580731 ]\n",
      " [0.7474166 ]\n",
      " [0.71906626]\n",
      " [0.8625043 ]\n",
      " [0.68273556]\n",
      " [0.886802  ]] \n",
      "Correct (Y):  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  0.76679844\n"
     ]
    }
   ],
   "source": [
    "# Lab 5 Logistic Regression Classifier\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "xy = np.loadtxt('data/data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "#x데이터 y데이터 구분해서 긁어오기\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(x_data.shape, y_data.shape)\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "#shape를 맞춰야함  x 8개. y는 1개\n",
    "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(-tf.matmul(X, W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y): \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv reading using tf.decode_csv\n",
    "try other classification data from kaggle\n",
    "https://www.kaggle.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
